# ğŸ“„ RAG-Based Google Doc Chatbot (Gemini + FAISS + Sentence Transformers)

A full-stack **Retrieval-Augmented Generation (RAG)** chatbot that automatically ingests content from a publicly shared Google Document and answers user queries with **accurate, citation-grounded responses**.

The system uses **Sentence Transformers for embeddings**, **FAISS for vector search**, and **Google Gemini (latest SDK)** for answer generation. It includes a **FastAPI backend** and a **web-based HTML/CSS/JS frontend UI**.

---

## ğŸš€ Features

- âœ… Automatic Google Doc ingestion (no manual uploads)
- âœ… Structured document parsing (section-aware)
- âœ… Semantic chunking with overlap
- âœ… Dense vector embeddings (Sentence Transformers)
- âœ… Fast similarity search using FAISS
- âœ… Gemini-powered grounded answer generation
- âœ… Inline section citations
- âœ… Multi-source scalable architecture
- âœ… FastAPI backend API
- âœ… Web chat UI (HTML/CSS/JS)
- âœ… Config-driven pipeline
- âœ… Production-ready modular design

---

## ğŸ— System Architecture

```text
Public Google Doc Link
        â†“
Ingestion Layer
        â†“
Structured Parsing
        â†“
Semantic Chunking
        â†“
Sentence Transformer Embeddings
        â†“
FAISS Vector Index
        â†“
Query Embedding
        â†“
Similarity Search
        â†“
Gemini RAG Generation
        â†“
FastAPI Backend
        â†“
HTML/JS Frontend UI

```

---

## ğŸ“‚ Project Folder Structure

```text
rag-chatbot/
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ fetch_doc.py
â”‚   â”œâ”€â”€ normalize.py
â”‚   â””â”€â”€ run_ingestion.py
â”‚
â”œâ”€â”€ chunking/
â”‚   â”œâ”€â”€ semantic_chunker.py
â”‚   â””â”€â”€ run_chunking.py
â”‚
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ embedder.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â””â”€â”€ run_embedding.py
â”‚
â”œâ”€â”€ retrieval/
â”‚   â””â”€â”€ retriever.py
â”‚
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ rag_pipeline.py
â”‚
â”‚
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ frontend/
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â”œâ”€â”€ style.css
â”‚   â”‚   â””â”€â”€ app.js
â”‚   â”‚
â”‚   â””â”€â”€ backend/
â”‚       â””â”€â”€ app.py     (FastAPI)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ vector_db/
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

---

## âš™ Tech Stack

| Component             | Technology                               |
| --------------------- | ---------------------------------------- |
| LLM                   | Google Gemini (google-genai SDK)         |
| Embeddings            | Sentence Transformers (all-MiniLM-L6-v2) |
| Vector DB             | FAISS                                    |
| Backend               | FastAPI                                  |
| Frontend              | HTML, CSS, JavaScript                    |
| Config                | YAML                                     |
| Environment Variables | python-dotenv                            |

---

## ğŸ”‘ Prerequisites

- Python 3.9+
- Google Gemini API Key
- Public Google Document link

---

## ğŸ”§ Installation

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/yourusername/rag-chatbot.git
cd rag-chatbot
```

### 2ï¸âƒ£ Install Dependencies

pip install -r requirements.txt

### 3ï¸âƒ£ Set Environment Variables

Create .env file:

GEMINI_API_KEY=your_api_key_here

### 4ï¸âƒ£ Update Config File

config/config.yaml

google_doc_url: "PASTE_PUBLIC_GOOGLE_DOC_LINK"

embedding:
model_name: all-MiniLM-L6-v2

retrieval:
top_k: 3

gemini:
model_name: gemini-1.5-flash
temperature: 0.2
max_output_tokens: 1024

### â–¶ Pipeline Execution (Step-by-Step)

âœ… Step 1 â€” Document Ingestion
python ingestion/run_ingestion.py
Fetches Google Doc and creates structured document.

âœ… Step 2 â€” Semantic Chunking
python chunking/run_chunking.py
Splits document into embedding-safe chunks.

âœ… Step 3 â€” Embedding + Vector Indexing
python embeddings/run_embedding.py
Creates FAISS vector database.

âœ… Step 4 â€” RAG Testing (CLI)
python rag/test_rag.py

Test question answering in terminal.
